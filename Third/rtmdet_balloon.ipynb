{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gS4VUn0esAPF",
        "outputId": "9cfe63b4-ee0b-45df-9e1b-b83c87077356"
      },
      "outputs": [],
      "source": [
        "# Check nvcc version\n",
        "!nvcc -V\n",
        "# Check GCC version\n",
        "!gcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKMrVfgC1DAA",
        "outputId": "12657500-dc13-4e2b-f161-8bf71d48406a"
      },
      "outputs": [],
      "source": [
        "from mmengine.utils import get_git_hash\n",
        "from mmengine.utils.dl_utils import collect_env as collect_base_env\n",
        "\n",
        "import mmdet\n",
        "\n",
        "# 环境信息收集和打印\n",
        "def collect_env():\n",
        "    \"\"\"Collect the information of the running environments.\"\"\"\n",
        "    env_info = collect_base_env()\n",
        "    env_info['MMDetection'] = f'{mmdet.__version__}+{get_git_hash()[:7]}'\n",
        "    return env_info\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    for name, val in collect_env().items():\n",
        "        print(f'{name}: {val}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Fxu3zQ0ptt_5"
      },
      "source": [
        "# 1 数据集准备和可视化\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "YNYvdTTXvOVi",
        "outputId": "6247fd3c-9a0c-410a-8aff-53c4e6dd5228"
      },
      "outputs": [],
      "source": [
        "# 数据集可视化\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "original_images = []\n",
        "images = []\n",
        "texts = []\n",
        "plt.figure(figsize=(16, 5))\n",
        "\n",
        "image_paths= [filename for filename in os.listdir('./balloon_dataset/images')][:8]\n",
        "\n",
        "for i,filename in enumerate(image_paths):\n",
        "    name = os.path.splitext(filename)[0]\n",
        "\n",
        "    image = Image.open('balloon_dataset/images/'+filename).convert(\"RGB\")\n",
        "  \n",
        "    plt.subplot(2, 4, i+1)\n",
        "    plt.imshow(image)\n",
        "    plt.title(f\"{filename}\")\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2IUzqNdvh9i"
      },
      "source": [
        "我们也提供了 coco json 标注，用户可以直接使用，而无需自己重新标注。COCO Json 可视化如下所示"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "LH0DPnR6viqB",
        "outputId": "dcec492d-0eaf-474f-fb35-39891213c83e"
      },
      "outputs": [],
      "source": [
        "from pycocotools.coco import COCO\n",
        "import numpy as np\n",
        "import os.path as osp\n",
        "from matplotlib.collections import PatchCollection\n",
        "from matplotlib.patches import Polygon\n",
        "\n",
        "def apply_exif_orientation(image):\n",
        "    _EXIF_ORIENT = 274\n",
        "    if not hasattr(image, 'getexif'):\n",
        "        return image\n",
        "\n",
        "    try:\n",
        "        exif = image.getexif()\n",
        "    except Exception:\n",
        "        exif = None\n",
        "\n",
        "    if exif is None:\n",
        "        return image\n",
        "\n",
        "    orientation = exif.get(_EXIF_ORIENT)\n",
        "\n",
        "    method = {\n",
        "        2: Image.FLIP_LEFT_RIGHT,\n",
        "        3: Image.ROTATE_180,\n",
        "        4: Image.FLIP_TOP_BOTTOM,\n",
        "        5: Image.TRANSPOSE,\n",
        "        6: Image.ROTATE_270,\n",
        "        7: Image.TRANSVERSE,\n",
        "        8: Image.ROTATE_90,\n",
        "    }.get(orientation)\n",
        "    if method is not None:\n",
        "        return image.transpose(method)\n",
        "    return image\n",
        "\n",
        "\n",
        "def show_bbox_only(coco, anns, show_label_bbox=True, is_filling=True):\n",
        "    \"\"\"Show bounding box of annotations Only.\"\"\"\n",
        "    if len(anns) == 0:\n",
        "        return\n",
        "\n",
        "    ax = plt.gca()\n",
        "    ax.set_autoscale_on(False)\n",
        "\n",
        "    image2color = dict()\n",
        "    for cat in coco.getCatIds():\n",
        "        image2color[cat] = (np.random.random((1, 3)) * 0.7 + 0.3).tolist()[0]\n",
        "\n",
        "    polygons = []\n",
        "    colors = []\n",
        "\n",
        "    for ann in anns:\n",
        "        color = image2color[ann['category_id']]\n",
        "        bbox_x, bbox_y, bbox_w, bbox_h = ann['bbox']\n",
        "        poly = [[bbox_x, bbox_y], [bbox_x, bbox_y + bbox_h],\n",
        "                [bbox_x + bbox_w, bbox_y + bbox_h], [bbox_x + bbox_w, bbox_y]]\n",
        "        polygons.append(Polygon(np.array(poly).reshape((4, 2))))\n",
        "        colors.append(color)\n",
        "\n",
        "        if show_label_bbox:\n",
        "            label_bbox = dict(facecolor=color)\n",
        "        else:\n",
        "            label_bbox = None\n",
        "\n",
        "        ax.text(\n",
        "            bbox_x,\n",
        "            bbox_y,\n",
        "            '%s' % (coco.loadCats(ann['category_id'])[0]['name']),\n",
        "            color='white',\n",
        "            bbox=label_bbox)\n",
        "\n",
        "    if is_filling:\n",
        "        p = PatchCollection(\n",
        "            polygons, facecolor=colors, linewidths=0, alpha=0.4)\n",
        "        ax.add_collection(p)\n",
        "    p = PatchCollection(\n",
        "        polygons, facecolor='none', edgecolors=colors, linewidths=2)\n",
        "    ax.add_collection(p)\n",
        "\n",
        "    \n",
        "coco = COCO('./balloon_dataset/annotations/test.json')\n",
        "image_ids = coco.getImgIds()\n",
        "np.random.shuffle(image_ids)\n",
        "\n",
        "plt.figure(figsize=(16, 5))\n",
        "\n",
        "# 只可视化 8 张图片\n",
        "for i in range(8):\n",
        "    image_data = coco.loadImgs(image_ids[i])[0]\n",
        "    image_path = osp.join('./balloon_dataset/images',image_data['file_name'])\n",
        "    annotation_ids = coco.getAnnIds(\n",
        "            imgIds=image_data['id'], catIds=[], iscrowd=0)\n",
        "    annotations = coco.loadAnns(annotation_ids)\n",
        "    \n",
        "    ax = plt.subplot(2, 4, i+1)\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    \n",
        "    # 这行代码很关键，否则可能图片和标签对不上\n",
        "    image=apply_exif_orientation(image)\n",
        "    \n",
        "    ax.imshow(image)\n",
        "    \n",
        "    show_bbox_only(coco, annotations)\n",
        "    \n",
        "    plt.title(f\"{filename}\")\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "        \n",
        "plt.tight_layout()    "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8I_Gq5c5v-s7"
      },
      "source": [
        "# 2 自定义配置文件"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXyL9UOqwGuC"
      },
      "outputs": [],
      "source": [
        "# 配置文件路径位于该运行文件的同级目录 \n",
        "\"rtmdet_tiny_1xb12-40e_ballon.py\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "x42D5iYZ0bLq"
      },
      "source": [
        "\n",
        "# 3 训练前可视化验证\n",
        "\n",
        "我们可以采用 mmdet 提供的 `tools/analysis_tools/browse_dataset.py` 脚本来对训练前的 dataloader 输出进行可视化，确保数据部分没有问题。\n",
        "考虑到我们仅仅想可视化前几张图片，因此下面基于 browse_dataset.py 实现一个简单版本即可"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "id": "9HD30AlN0cRS",
        "outputId": "336d932f-2a9b-4a24-e985-92083b2c904b"
      },
      "outputs": [],
      "source": [
        "from mmdet.registry import DATASETS, VISUALIZERS\n",
        "from mmengine.config import Config\n",
        "from mmengine.registry import init_default_scope\n",
        "\n",
        "cfg = Config.fromfile('rtmdet_tiny_1xb12-40e_balloon.py')\n",
        "\n",
        "init_default_scope(cfg.get('default_scope', 'mmdet'))\n",
        "\n",
        "dataset = DATASETS.build(cfg.train_dataloader.dataset)\n",
        "visualizer = VISUALIZERS.build(cfg.visualizer)\n",
        "visualizer.dataset_meta = dataset.metainfo\n",
        "\n",
        "plt.figure(figsize=(16, 5))\n",
        "\n",
        "# 只可视化前 8 张图片\n",
        "for i in range(8):\n",
        "   item=dataset[i]\n",
        "\n",
        "   img = item['inputs'].permute(1, 2, 0).numpy()\n",
        "   data_sample = item['data_samples'].numpy()\n",
        "   gt_instances = data_sample.gt_instances\n",
        "   img_path = osp.basename(item['data_samples'].img_path)\n",
        "\n",
        "   gt_bboxes = gt_instances.get('bboxes', None)\n",
        "   gt_instances.bboxes = gt_bboxes.tensor\n",
        "   data_sample.gt_instances = gt_instances\n",
        "\n",
        "   visualizer.add_datasample(\n",
        "            osp.basename(img_path),\n",
        "            img,\n",
        "            data_sample,\n",
        "            draw_pred=False,\n",
        "            show=False)\n",
        "   drawed_image=visualizer.get_image()\n",
        "\n",
        "   plt.subplot(2, 4, i+1)\n",
        "   plt.imshow(drawed_image[..., [2, 1, 0]])\n",
        "   plt.title(f\"{osp.basename(img_path)}\")\n",
        "   plt.xticks([])\n",
        "   plt.yticks([])\n",
        "\n",
        "plt.tight_layout()    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fD59jaYY3veC"
      },
      "source": [
        "# 4 模型训练\n",
        "\n",
        "在验证数据流本身没有问题后，就可以开始进行训练了"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiSxY1U831Ov",
        "outputId": "01a636bc-0fcb-406d-aaef-d6d836b80dbc"
      },
      "outputs": [],
      "source": [
        "!python mmdetection/tools/train.py rtmdet_tiny_1xb12-40e_balloon.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nN840uwB88IM",
        "outputId": "53e00cfe-0fa1-4ecc-e554-e44a8848717a"
      },
      "outputs": [],
      "source": [
        "!python mmdetection/tools/test.py rtmdet_tiny_1xb12-40e_balloon.py work_dirs/rtmdet_tiny_1xb12-40e_balloon/best_coco/bbox_mAP_epoch_30.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbxgThf-9YdE"
      },
      "source": [
        "在测试阶段，你可以设置 --show-dir 将测试图片的真实值和预测值保存下来，然后进行深入分析。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZ5umkLA9wZT",
        "outputId": "ed439bc0-a4b2-4176-c972-d0d78736cb3b"
      },
      "outputs": [],
      "source": [
        "!python mmdetection/tools/test.py rtmdet_tiny_1xb12-40e_balloon.py work_dirs/rtmdet_tiny_1xb12-40e_balloon/best_coco/bbox_mAP_epoch_30.pth --show-dir results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfI3XvIm-JJn"
      },
      "source": [
        "会在 `work_dir/rtmdet_tiny_1xb12-40e_cat/当前时间戳/results/` 下生成测试图片，下面对前 8 张图片进行可视化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hwworoFc-W-Y",
        "outputId": "f752d085-ccee-40bf-c5f9-2208c5819599"
      },
      "outputs": [],
      "source": [
        "# 数据集可视化\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "plt.figure(figsize=(20, 20))\n",
        "\n",
        "# 你如果重新跑，这个时间戳是不一样的，需要自己修改\n",
        "root_path='work_dirs/rtmdet_tiny_1xb12-40e_balloon/20230610_172507/results/'\n",
        "image_paths= [filename for filename in os.listdir(root_path)][:4]\n",
        "\n",
        "for i,filename in enumerate(image_paths):\n",
        "    name = os.path.splitext(filename)[0]\n",
        "\n",
        "    image = Image.open(root_path+filename).convert(\"RGB\")\n",
        "  \n",
        "    plt.subplot(4, 1, i+1)\n",
        "    plt.imshow(image)\n",
        "    plt.title(f\"{filename}\")\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoaJHJkzFVfL"
      },
      "source": [
        "左边显示的是标注框，右边显示的是预测框。\n",
        "\n",
        "实际上 MMDetection 支持多种可视化后端，例如 TensorBoard 和 WandB，默认情况下是将图片保存到本地，用户只需要修改可视化部分配置即可轻松切换。如下所示\n",
        "\n",
        "以下配置只需要加到 `rtmdet_tiny_1xb12-40e_cat.py` 配置最后即可\n",
        "\n",
        "**(1) 同时使用本地和 WandB 后端**\n",
        "\n",
        "```python\n",
        "visualizer = dict(vis_backends = [dict(type='LocalVisBackend'), dict(type='WandbVisBackend')])\n",
        "```\n",
        "\n",
        "**(2) 仅仅使用 TensorBoard 后端**\n",
        "\n",
        "```python\n",
        "visualizer = dict(vis_backends = [dict(type='TensorboardVisBackend')])\n",
        "```\n",
        "修改配置后重新运行 test.py 即可在 WandB 和 TensorBoard 前端界面查看 图片和 log 等。\n",
        "\n",
        "如果想对单张图片进行推理，你可以直接使用 `mmdetection/demo/image_demo.py` 脚本"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPU1GNxoICgf",
        "outputId": "77424683-3837-4f0b-f19e-3e971628f59a"
      },
      "outputs": [],
      "source": [
        "!python mmdetection/demo/image_demo.py my_balloons/1.jpg rtmdet_tiny_1xb12-40e_balloon.py --weights work_dirs/rtmdet_tiny_1xb12-40e_balloon/best_coco/bbox_mAP_epoch_30.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KA_BPPAfIqQ3",
        "outputId": "31c4f8d8-70b6-41c4-af59-e9a7d12f1e53"
      },
      "outputs": [],
      "source": [
        "Image.open('outputs/vis/1.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLuD4nANJEdP"
      },
      "source": [
        "# 6 可视化分析\n",
        "\n",
        "可视化分析包括特征图可视化以及类似 Grad CAM 等可视化分析手段。不过由于 MMDetection 中还没有实现，我们可以直接采用 MMYOLO 中提供的功能和脚本。MMYOLO 是基于 MMDetection 开发，并且此案有了统一的代码组织形式，因此 MMDetection 配置可以直接在 MMYOLO 中使用，无需更改配置。\n",
        "\n",
        "## MMYOLO 环境和依赖安装"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lT8ee-LwLY3j"
      },
      "source": [
        "## 特征图可视化\n",
        "\n",
        "MMYOLO 中，将使用 MMEngine 提供的 `Visualizer` 可视化器进行特征图可视化，其具备如下功能：\n",
        "\n",
        "- 支持基础绘图接口以及特征图可视化。\n",
        "- 支持选择模型中的不同层来得到特征图，包含 `squeeze_mean` ， `select_max` ， `topk` 三种显示方式，用户还可以使用 `arrangement` 自定义特征图显示的布局方式。\n",
        "\n",
        "你可以调用 `demo/featmap_vis_demo.py` 来简单快捷地得到可视化结果，为了方便理解，将其主要参数的功能梳理如下：\n",
        "\n",
        "- `img`：选择要用于特征图可视化的图片，支持单张图片或者图片路径列表。\n",
        "\n",
        "- `config`：选择算法的配置文件。\n",
        "\n",
        "- `checkpoint`：选择对应算法的权重文件。\n",
        "\n",
        "- `--out-file`：将得到的特征图保存到本地，并指定路径和文件名。\n",
        "\n",
        "- `--device`：指定用于推理图片的硬件，`--device cuda：0`  表示使用第 1 张 GPU 推理，`--device cpu` 表示用 CPU 推理。\n",
        "\n",
        "- `--score-thr`：设置检测框的置信度阈值，只有置信度高于这个值的框才会显示。\n",
        "\n",
        "- `--preview-model`：可以预览模型，方便用户理解模型的特征层结构。\n",
        "\n",
        "- `--target-layers`：对指定层获取可视化的特征图。\n",
        "\n",
        "  - 可以单独输出某个层的特征图，例如： `--target-layers backbone` ,  `--target-layers neck` ,  `--target-layers backbone.stage4` 等。\n",
        "  - 参数为列表时，也可以同时输出多个层的特征图，例如： `--target-layers backbone.stage4 neck` 表示同时输出 backbone 的 stage4 层和 neck 的三层一共四层特征图。\n",
        "\n",
        "- `--channel-reduction`：输入的 Tensor 一般是包括多个通道的，`channel_reduction` 参数可以将多个通道压缩为单通道，然后和图片进行叠加显示，有以下三个参数可以设置：\n",
        "\n",
        "  - `squeeze_mean`：将输入的 C 维度采用 mean 函数压缩为一个通道，输出维度变成 (1, H, W)。\n",
        "  - `select_max`：将输入先在空间维度 sum，维度变成 (C, )，然后选择值最大的通道。\n",
        "  - `None`：表示不需要压缩，此时可以通过 `topk` 参数可选择激活度最高的 `topk` 个特征图显示。\n",
        "\n",
        "- `--topk`：只有在 `channel_reduction` 参数为 `None` 的情况下， `topk` 参数才会生效，其会按照激活度排序选择 `topk` 个通道，然后和图片进行叠加显示，并且此时会通过 `--arrangement` 参数指定显示的布局，该参数表示为一个数组，两个数字需要以空格分开，例如： `--topk 5 --arrangement 2 3` 表示以 `2行 3列` 显示激活度排序最高的 5 张特征图， `--topk 7 --arrangement 3 3` 表示以 `3行 3列` 显示激活度排序最高的 7 张特征图。\n",
        "\n",
        "  - 如果 topk 不是 -1，则会按照激活度排序选择 topk 个通道显示。\n",
        "  - 如果 topk = -1，此时通道 C 必须是 1 或者 3 表示输入数据是图片，否则报错提示用户应该设置 `channel_reduction` 来压缩通道。\n",
        "\n",
        "- 考虑到输入的特征图通常非常小，函数默认将特征图进行上采样后方便进行可视化。\n",
        "\n",
        "**注意：当图片和特征图尺度不一样时候，`draw_featmap` 函数会自动进行上采样对齐。如果你的图片在推理过程中前处理存在类似 Pad 的操作此时得到的特征图也是 Pad 过的，那么直接上采样就可能会出现不对齐问题。**\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PbRNoOtkXx4N"
      },
      "source": [
        "计划采用 balloon_dataset/images/155815494_800fc9aa32_b.jpg 图片进行后续可视化分析"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TK7q2BZZXbxy",
        "outputId": "2b8f87a8-296c-4bf9-835b-0364de003c21"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "img = cv2.imread('balloon_dataset/images/155815494_800fc9aa32_b.jpg')\n",
        "h,w=img.shape[:2]\n",
        "resized_img = cv2.resize(img, (640, 640))\n",
        "cv2.imwrite('resized_image.jpg', resized_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4LTwQO0ZDvu"
      },
      "source": [
        "**1. 可视化 backbone 输出的 3 个通道**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ppe6g2MqMo9Y",
        "outputId": "2784e63b-bdb2-4c5d-9687-ab5ccfa85b09"
      },
      "outputs": [],
      "source": [
        "!python mmyolo/demo/featmap_vis_demo.py \\\n",
        "      resized_image.jpg \\\n",
        "      ./rtmdet_tiny_1xb12-40e_balloon.py \\\n",
        "      ./work_dirs/rtmdet_tiny_1xb12-40e_balloon/best_coco/bbox_mAP_epoch_30.pth  \\\n",
        "      --target-layers backbone  \\\n",
        "      --channel-reduction squeeze_mean\n",
        "Image.open('output/resized_image.jpg')     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qy2Pw_ldao-M"
      },
      "source": [
        "上图中绘制的 3 个输出特征图对应大中小输出特征图。由于本次训练的 backbone 实际上没有参与训练，从上图可以看到，大物体 cat 是在小特征图进行预测，这符合目标检测分层检测思想。\n",
        "\n",
        "**2. 可视化 neck 输出的 3 个通道**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "u0i8ScCIa0RZ",
        "outputId": "4a320bf3-c9fa-421c-9bb5-7542fe60e3f1"
      },
      "outputs": [],
      "source": [
        "!python mmyolo/demo/featmap_vis_demo.py \\\n",
        "      resized_image.jpg \\\n",
        "      ./rtmdet_tiny_1xb12-40e_balloon.py \\\n",
        "      ./work_dirs/rtmdet_tiny_1xb12-40e_balloon/best_coco/bbox_mAP_epoch_30.pth  \\\n",
        "      --target-layers neck  \\\n",
        "      --channel-reduction squeeze_mean\n",
        "Image.open('output/resized_image.jpg') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLi1_1V_a993"
      },
      "source": [
        "从上图可以看出，由于 neck 是参与训练的，并且 FPN 间的信息融合导致输出特征图更加聚集\n",
        "\n",
        "## Grad-Based CAM 可视化\n",
        "\n",
        "由于目标检测的特殊性，这里实际上可视化的并不是 CAM 而是 Grad Box AM。使用前需要先安装 grad-cam 库\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2NsAzjHbffv",
        "outputId": "26410f28-bbb8-473c-ddc8-013834916c06"
      },
      "outputs": [],
      "source": [
        "!pip install \"grad-cam\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsyeTLT7bpUc"
      },
      "source": [
        "**(a) 查看 neck 输出的最小输出特征图的 Grad CAM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 786
        },
        "id": "21N4PHN-brUM",
        "outputId": "993141d7-6524-4415-b058-80cd0850e0d7"
      },
      "outputs": [],
      "source": [
        "!python mmyolo/demo/boxam_vis_demo.py \\\n",
        "      resized_image.jpg \\\n",
        "      ./rtmdet_tiny_1xb12-40e_balloon.py \\\n",
        "      ./work_dirs/rtmdet_tiny_1xb12-40e_balloon/best_coco/bbox_mAP_epoch_30.pth  \\\n",
        "      --target-layer neck.out_convs[1]\n",
        "Image.open('output/resized_image.jpg')       "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EX77NdndEWd"
      },
      "source": [
        "可以看出效果较好\n",
        "\n",
        "**(b) 查看 neck 输出的最大输出特征图的 Grad CAM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 786
        },
        "id": "GMvGNEVSdDYX",
        "outputId": "9a8c7606-9242-442a-a8c3-9b90fc61fece"
      },
      "outputs": [],
      "source": [
        "!python mmyolo/demo/boxam_vis_demo.py \\\n",
        "      resized_image.jpg \\\n",
        "      ./rtmdet_tiny_1xb12-40e_balloon.py \\\n",
        "      ./work_dirs/rtmdet_tiny_1xb12-40e_balloon/best_coco/bbox_mAP_epoch_30.pth  \\\n",
        "      --target-layer neck.out_convs[0]\n",
        "Image.open('output/resized_image.jpg')     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri7xKJF7dsbl"
      },
      "source": [
        "可以发现由于大物体不会在该层预测，因此梯度可视化是 0，符合预期。"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
